---
title: "Instantiating ResNet50 Model and Setup for Training, mAP and mAR Evaluation on Unseen Validation Dataset, and Data Visualisation"
date: 03-10-2024
date-format: short
---

### Purpose:
Having written the code necessary to instantiate, train, and evaluate a ResNet50 model, I need to evaluate its performance over several epochs. This will help to validate the code functions as intended, and to guide future development.

Here, I attempt to train a Resnet50 faster RCNN model for 10 epochs using src/Plate_Image_Dataset.py and src/helper_training_functions.py. Then evaluate its mean average precision and recall, to be visualised in line graph.

This script uses code from the following src files:
- src/Plate_Image_Dataset.py - custom class that handles storing and accessing images and their corresponding bounding box vertices.
- src/helper_training_functions.py - a group of useful helper functions I've written. For example, 'get_model_instance_object_detection' should return a resnet50 convolutional layer with default weights with a custom region proposal network with classifier and bounding box regression heads. 

It may also be helpful to visualise the model architecture. There are libraries for this, one of which is '[pytorchviz](https://github.com/szagoruyko/pytorchviz)'. If useful, I will create such a script [here](docs/scripts/inspect_architecture.qmd).

For reference, here is a useful [pytorch tutorial](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html).

### Programme Overview:

#### Imports:
```{python}
from src import Plate_Image_Dataset, helper_training_functions
import torch

from torchvision.transforms.v2 import functional as F
from pathlib import Path
from typing import Dict, Union
from torchvision.models.detection.faster_rcnn import fasterrcnn_resnet50_fpn_v2, FastRCNNPredictor, FasterRCNN_ResNet50_FPN_V2_Weights
from torchvision.transforms import v2 as T
import lib.utils as utils
from lib.engine import train_one_epoch, evaluate 
import os
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import numpy as np
import PIL
from torchvision.utils import draw_bounding_boxes
from torchvision.io import read_image
from torch import nn
```
**Notes:** when running on the cluster, change any import statements that import modules defined within the project directory (this includes some files in lib/). Here is an example:
```{python}
#| eval: false
from src import Plate_Image_Dataset, helper_training_functions
# to...
from SC_TSL_15092024_plate_detect.src import PLate_Image_Dataset, helper_training_functions

```

#### Setting up directories and instantiating model...
```{python}
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')

project_dir_root: Path= Path.cwd() # 'SC_TSL_15092024_Plate_Detect/' type PosixPath for UNIX, WindowsPath for windows...
print(f'Project root directory: {str(project_dir_root)}')

annotations_file: Path = project_dir_root.parents[2].joinpath('train', 'labels.csv')
print(f'Training labels csv file: {annotations_file}')

img_dir: Path= project_dir_root.parents[2].joinpath('train', 'images', 'positives')  # 'SC_TSL_15092024_Plate_Detect/train/images/positives/' on UNIX systems
print(f'Training dataset directory: {img_dir}')

num_class = 2 # plate or background
# creates resnet50 v2 faster r cnn model with new head for class classification
model, preprocess = helper_training_functions.get_model_instance_object_detection(num_class)
# move model to the right device
model.to(device)
```
**Breakdown:** \
- 'preprocess' stores the input data transforms that take place just before the forward pass through the network. In this case, preprocess converts Tensor image, PIL image, or NumPy ndarray types into FloatTensor and scales pixel intensities in range [0.,1.] \

#### Instantiating Plate_Image_Dataset class and creating training and validation subsets...
```{python}
dataset: Plate_Image_Dataset = Plate_Image_Dataset.Plate_Image_Dataset(
        img_dir=str(img_dir), 
        annotations_file=str(annotations_file),
        transforms=preprocess, 
        )

# split the dataset in train and test set
dataset_size = len(dataset)
validation_size = min(50, int(dataset_size // 5))  # Use 20% of data for testing, or 50 samples, whichever is smaller
indices = [int(i) for i in torch.randperm(dataset_size).tolist()]

dataset_validation = torch.utils.data.Subset(dataset, indices[-validation_size:])
dataset_train = torch.utils.data.Subset(dataset, indices[:-validation_size])
```
**Breakdown:** \
- Plate_Image_Dataset is a custom dataset class used to handle parsing the csv file for bounding box vertices, associating them with the correct image using a dictionary, and handling retrieval of this information. For a more detailed overview, see [Plate_Image_Dataset.qmd](Plate_Image_Datset.qmd). \
- In order to create validation and training subsets of the positive samples (i.e., the images *with* at least one plate labelled), I created a randomly arranged list of indices (where len(indices) == the number of samples in the dataset). The validation subset size is equal to 20% of the superset, or 50 samples, whichever is smallest. I did this because I would like to implement data augmentation later after validation of the program's functionality. \

#### Instantiating Pytorch DataLoaders for train and validation subsets...
```{python}
data_loader = torch.utils.data.DataLoader(
    dataset_train,
    batch_size=1,
    shuffle=True,
    collate_fn=utils.collate_fn
)

data_loader_test = torch.utils.data.DataLoader(
    dataset_validation,
    batch_size=1,
    shuffle=False,
    collate_fn=utils.collate_fn
)
```
**Breakdown:** \
- See [here](https://pytorch.org/docs/stable/data.html) Pytorch's documentation for DataLoader. DataLoader fetches and collates together individual samples into batches - i.e., it acts as a sampler. It does so by squeezing on a batch dimension (typically the first) to Tensors. It also provides an iterable over the given dataset. \
- In this case, the Image_Plate_Dataset class is a map-style dataset, as it implements __getitem__() and __len__(), and stores samples with their associated labels and metadata at a shared index. \
- If shuffle == True, data is reshuffled at every epoch. \

#### Calling train, evaluate, and plot helper functions...
```{python}
#| eval: false
num_epochs = 1
precedent_epoch = 0

epoch, loss_metrics = helper_training_functions.train(model, data_loader, data_loader_test, device, num_epochs, precedent_epoch)

eval_metrics = helper_training_functions.evaluate_model(model, data_loader_test,device)

helper_training_functions.plot_eval_metrics(eval_metrics, epoch)


print("\n -end-")

```
**Breakdown:** \
- See [helper_training_functions.qmd](helper_training_functions.qmd) for detail on how these functions work.
- *Note* I have only set it to train for 1 epoch here just to show the output. I need to train for longer on cluster.

### Next step: Setup singularity container on the cluster and train for 10 epochs.
