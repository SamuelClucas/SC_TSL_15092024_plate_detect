---
title: "Establishing a GoHREP for Analysis 0002*"
date: 09-10-2024
date-format: short
---

## Introduction: \
There are numerous object detection model architectures available. \
Typically, they comprise: a convolutional module used for feature extraction; some mechanism for identifying Regions of Interest (ROIs) (for example, by [selective search](https://link.springer.com/article/10.1007/s11263-013-0620-5), or by a [Region Proposal Network] (RPN) that uses 'anchors' and is integrated within the model); and classification/masking/bounding box regression heads. \
Chosen somewhat arbitrarily, I will first code and train a Faster R-CNN architecture. There are others that might be worth exploring (e.g., You Only Look Once (YOLO), Single-Shot Detector(SSD)), but I think implementing the former is more realistic given my inexperience with deep machine learning frameworks prior to this project. \

### Goal: \
Develop an object detection pipeline using a Faster R-CNN model trained on the dataset created in [analysis 0001](../0001_dataset_creation/) to facilitate the [imaging system's](https://github.com/SamuelClucas/SC_TSL_06082024_imaging_system_design) recognition of and navigation to growth plates inside the incubator. \

### Hypothesis: \
Can a Faster R-CNN model trained on [this](../../raw/) dataset identify and label plates with bounding boxes in a validation subset with a mean Average Precision (mAP) of greater than 50%, based on an Intersection over Union(IoU) metric. \

### Rationale: \
Real-time object detection using the Faster R-CNN architecture has been robustly established in the literature ([Shaoqing Ren et al., 2016](https://proceedings.neurips.cc/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf),[Yu Liu, 2018](https://ieeexplore.ieee.org/abstract/document/8695451), [Wenze Li, 2021](https://iopscience.iop.org/article/10.1088/1742-6596/1827/1/012085/meta)). \

Further to this, based on reading of the [Universal Approximation Theorem](https://mitliagkas.github.io/ift6085-2020/ift-6085-lecture-10-notes.pdf), it is reasonable to posit that given sufficient, representative, and clear training data, the network should be abe to detect plates in images to at least some degree of accuracy. The question is whether or not this accuracy is high enough to be practically useful. \

### Experimental Plan: \
- I will use PyTorch. Firstly, I need to write two custom dataset classes to handle storing and accessing images and their corresponding bounding box vertices for both the positives and negatives datasets (the latter to be used in [hard negatives mining](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123590120.pdf) to further optimise the model). \
- Once instantiated, this class is passed to PyTorch's DataLoader for training or evaluation, as outlined in this [pytorch tutorial](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html). I would like to write a helper_training_functions src file to be imported in training scripts to keep the latter concise and readable. \
- Training on the cluster requires that scripts don't need to download files at runtime. This will require a local Faster R-CNN class definition file. \
- [ResNet50](https://blog.roboflow.com/what-is-resnet-50/#:~:text=One%20such%20architecture%20is%20called,it%2C%20and%20categorize%20them%20accordingly.)'s COCO or ImageNet pre-trained weights aren't going to be useful. This is common sense. 'Non-lambertian' or transparent objects form a minority within these datasets, which isn't helpful in training a network to recognise an object that is transparent. For this reason, I will train a ResNet backbone (I'm not sure many layers this will have, perhaps 50-layer or 101-layer) on a transparent object dataset. Google's [cleargrasp](https://github.com/Shreeyak/cleargrasp/tree/master) project required the creation of [transparent object datasets](https://sites.google.com/view/transparent-objects). I will train the network on these first, with the hopes that the backbone will then be primed to extract features typical of transparent objects. \
- I will then freeze the backbone weights prior to training of the RPN layer, and the classification and bounding box regression heads. This model will undergo evaluation to answer the hypothesis. \

Next: [Creating a custom dataset class...](01_Plate_Image_Dataset.qmd)