---
title: "Instantiating ResNet50 Model and Setup for Training, mAP and mAR Evaluation on Unseen Validation Dataset, and Data Visualisation"
date: 03-10-2024
date-format: short
---

### Purpose: \
Having written the code necessary to instantiate, train, and evaluate a ResNet50 model, I need to evaluate its performance over several epochs. This will help to validate the code functions as intended, and to guide future development. \

Here, I attempt to setup, train, and evaluate a Resnet50 Faster R-CNN model for 10 epochs - using src/Plate_Image_Dataset.py and src/helper_training_functions.py - then evaluate its mean average precision and recall, to be visualised in a line graph. \

The implementation focuses on validating the core functionality of the object detection pipeline before scaling up to full training runs. \

This script uses code from the following src files: \
- src/[Plate_Image_Dataset.py](../../src/plate_detect/Plate_Image_Dataset.py) - custom class that handles storing and accessing images and their corresponding bounding box vertices. \
- src/[helper_training_functions.py](../../src/plate_detect/helper_training_functions.py) - a group of useful helper functions I've written. For example, 'get_model_instance_object_detection' should return a [ResNet50](https://pytorch.org/hub/pytorch_vision_resnet/) backbone ([ImageNet1K_V2 weights](https://pytorch.org/vision/0.18/models/generated/torchvision.models.resnet50.html#:~:text=By%20default%2C%20no%20pre%2Dtrained%20weights%20are%20used.)), with a Region Proposal Network, as well as classifier and bounding box regression heads. 

It may also be helpful to visualise the model architecture. There are libraries for this, one of which is '[pytorchviz](https://github.com/szagoruyko/pytorchviz)'. If useful, I will create such a script [here](docs/scripts/inspect_architecture.qmd). \

For reference, here is a useful [pytorch tutorial](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html). \
 
### Programme Overview:

#### Imports:
```{python}
from plate_detect import Plate_Image_Dataset, helper_training_functions
import torch
from torchvision.transforms.v2 import functional as F
from pathlib import Path
from typing import Dict, Union
from torchvision.models.detection.faster_rcnn import fasterrcnn_resnet50_fpn_v2, FastRCNNPredictor, FasterRCNN_ResNet50_FPN_V2_Weights
from torchvision.transforms import v2 as T
import torchvision_deps.T_and_utils.utils as utils
from torchvision_deps.engine import train_one_epoch, evaluate 
import os
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import numpy as np
import PIL
from torchvision.utils import draw_bounding_boxes
from torchvision.io import read_image
from torch import nn
```
**Notes:** when running on the cluster, change any import statements for packages defined within the project directory (see [src](../../src/)). Here is an example:
```{python}
#| eval: false
from src import Plate_Image_Dataset, helper_training_functions
# to...
from SC__plate_detect.plate_detect import PLate_Image_Dataset, helper_training_functions

```

#### Setting up directories and instantiating model...
```{python}
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')

project_dir_root: Path= Path.cwd() # 'SC_TSL_15092024_Plate_Detect/' type PosixPath for UNIX, WindowsPath for windows...
print(f'Project root directory: {str(project_dir_root)}')

annotations_file: Path = project_dir_root.parents[1].joinpath('lib', 'labels.csv')
print(f'Training labels csv file: {annotations_file}')

img_dir: Path= project_dir_root.parents[1].joinpath('raw', 'positives')  # 'SC_TSL_15092024_Plate_Detect/train/images/positives/' on UNIX systems
print(f'Training dataset directory: {img_dir}')

num_class = 2 # plate or background
# creates resnet50 v2 faster r cnn model with new head for class classification
model, preprocess = helper_training_functions.get_model_instance_object_detection(num_class)
# move model to the right device
model.to(device)
```
**Breakdown:** \
- Uses 'Compute Unified Device Architecture' ([CUDA](https://blogs.nvidia.com/blog/what-is-cuda-2/) if available, falls back to CPU. \
- Initializes ResNet50 Faster R-CNN with pretrained weights. \
- 'preprocess' stores the input data transforms that take place just before the forward pass through the network. In this case, preprocess converts Tensor image, PIL image, or NumPy ndarray types into FloatTensor and scales pixel intensities in range [0.,1.] \

#### Instantiating Plate_Image_Dataset class and creating training and validation subsets...
```{python}
dataset: Plate_Image_Dataset = Plate_Image_Dataset.Plate_Image_Dataset(
        img_dir=str(img_dir), 
        annotations_file=str(annotations_file),
        transforms=preprocess, 
        )

# split the dataset in train and test set
dataset_size = len(dataset)
validation_size = min(50, int(dataset_size // 5))  # Use 20% of data for testing, or 50 samples, whichever is smaller
indices = [int(i) for i in torch.randperm(dataset_size).tolist()]

dataset_validation = torch.utils.data.Subset(dataset, indices[-validation_size:])
dataset_train = torch.utils.data.Subset(dataset, indices[:-validation_size])
```
**Breakdown:** \
- Plate_Image_Dataset is a custom dataset class used to handle parsing the csv file for bounding box vertices, associating them with the correct image using a dictionary, and handling retrieval of this information. For a more detailed overview, see [Plate_Image_Dataset.md](01_Plate_Image_Dataset.md). \
- In order to create validation and training subsets of the positive samples (i.e., the images *with* at least one plate labelled), I created a randomly arranged list of indices (where len(indices) == the number of samples in the dataset). The validation subset size is equal to 20% of the superset, or 50 samples, whichever is smallest. When I implement dataset augmentation I will scale this up. \

#### Instantiating Pytorch DataLoaders for train and validation subsets...
```{python}
data_loader = torch.utils.data.DataLoader(
    dataset_train,
    batch_size=1,
    shuffle=True,
    collate_fn=utils.collate_fn
)

data_loader_test = torch.utils.data.DataLoader(
    dataset_validation,
    batch_size=1,
    shuffle=False,
    collate_fn=utils.collate_fn
)
```
**Breakdown:** \
- See [here](https://pytorch.org/docs/stable/data.html) Pytorch's documentation for DataLoader. DataLoader fetches and collates together individual samples into batches - i.e., it acts as a sampler. It does so by squeezing on a batch dimension (typically the first) to Tensors. It also provides an iterable over the given dataset. \
- In this case, the Image_Plate_Dataset class is a map-style dataset, as it implements __getitem__() and __len__(), and stores samples with their associated labels and metadata at a shared index. \
- If shuffle == True, data is reshuffled at every epoch. \

#### Calling train, evaluate, and plot helper functions...
```{python}
save_dir = 'results'
num_epochs = 1
precedent_epoch = 0

epoch, loss_metrics = helper_training_functions.train(model, data_loader, data_loader_test, device, num_epochs, precedent_epoch, save_dir)

eval_metrics = helper_training_functions.evaluate_model(model, data_loader_test,device)

helper_training_functions.plot_eval_metrics(eval_metrics, epoch)


print("\n -end-")

```
**Breakdown:** \
- See [helper_training_functions.qmd](helper_training_functions.qmd) for detail on how these functions work. Briefly: \
    1. Training function handles: \
        - Optimisation using SGD with momentum  \
        - Learning rate scheduling \
        - Checkpoint saving \
        - Loss tracking \
    2. Evaluation produces:  \
        - Mean Average Precision (mAP) \
        - Mean Average Recall (mAR) \
        - Performance metrics across IoU thresholds \
    3. Visualisation plot includes: \
        - Training loss curves (currently commented out...) \
        - Precision and recall metrics \
- *Note* I have only set it to train for 1 epoch here just to show the output. I need to train for longer on cluster. \

### Next step: Setup singularity container on the cluster and [train for 10 epochs for baseline performance assessment, using evaluation plot to guide revisions...](04_ResNet50_training.md)
