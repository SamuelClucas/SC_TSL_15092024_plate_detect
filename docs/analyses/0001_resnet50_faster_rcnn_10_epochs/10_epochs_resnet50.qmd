---
title: "Evaluating checkpoints/epoch_0 mAP and mAR on unseen validation dataset"
date: 03-10-2024
date-format: short
---

### Purpose:
Train a Resnet50 faster RCNN model for 10 epochs using src/Plate_Image_Dataset.py and src/helper_training_functions.py. Then evaluate its mean average precision and recall visualised in plots.

- src/Plate_Image_Dataset.py - custom class that handles storing and accessing images and their corresponding bounding box vertices.
- src/helper_training_functions.py - a group of useful helper functions I've written. For example, 'get_model_instance_object_detection' should return a resnet50 convolutional layer with default weights with a custom region proposal network with classifier and bounding box regression heads. 
- the architecture of the model returned by this helper function needs to be validated. See [here](docs/scripts/inspect_architecture.qmd).
- [here](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html) is the tutorial I referenced when creating this script.

### Programme Overview:

#### Imports:
```{python}
from src import Plate_Image_Dataset, helper_training_functions
import torch

from torchvision.transforms.v2 import functional as F
from pathlib import Path
from typing import Dict, Union
from torchvision.models.detection.faster_rcnn import fasterrcnn_resnet50_fpn_v2, FastRCNNPredictor, FasterRCNN_ResNet50_FPN_V2_Weights
from torchvision.transforms import v2 as T
import lib.utils as utils
from lib.engine import train_one_epoch, evaluate 
import os
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import numpy as np
import PIL
from torchvision.utils import draw_bounding_boxes
from torchvision.io import read_image
from torch import nn
```

### if __name__ == '__main__':
#### Setting up directories and instantiating model instance...
```{python}
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')

project_dir_root: Path= Path.cwd() # 'SC_TSL_15092024_Plate_Detect/' type PosixPath for UNIX, WindowsPath for windows...
print(f'Project root directory: {str(project_dir_root)}')

annotations_file: Path = project_dir_root.parents[2].joinpath('train', 'labels.csv')
print(f'Training labels csv file: {annotations_file}')

img_dir: Path= project_dir_root.parents[2].joinpath('train', 'images', 'positives')  # 'SC_TSL_15092024_Plate_Detect/train/images/positives/' on UNIX systems
print(f'Training dataset directory: {img_dir}')

num_class = 2 # plate or background
# creates resnet50 v2 faster r cnn model with new head for class classification
model, preprocess = helper_training_functions.get_model_instance_object_detection(num_class)
# move model to the right device
model.to(device)
```
**Breakdown:** \
- stepwise breakdown \

#### Instantiating Plate_Image_Dataset class and creating training and validation subsets...
```{python}
dataset: Plate_Image_Dataset = Plate_Image_Dataset.Plate_Image_Dataset(
        img_dir=str(img_dir), 
        annotations_file=str(annotations_file),
        transforms=preprocess, # converts Tensor image, PIL image, NumPy ndarray into FloatTensor and scales pixel intensities in range [0.,1.].
        )

# split the dataset in train and test set
dataset_size = len(dataset)
test_size = min(50, int(dataset_size // 5))  # Use 20% of data for testing, or 50 samples, whichever is smaller
indices = [int(i) for i in torch.randperm(dataset_size).tolist()]

dataset_validation = torch.utils.data.Subset(dataset, indices[-test_size:])
dataset_train = torch.utils.data.Subset(dataset, indices[:-test_size])
```

**Breakdown:** \
- stepwise breakdown \

#### Instantiating Plate_Image_Dataset class and creating training and validation subsets...
```{python}
data_loader = torch.utils.data.DataLoader(
    dataset_train,
    batch_size=4,
    shuffle=True,
    collate_fn=utils.collate_fn
)

data_loader_test = torch.utils.data.DataLoader(
    dataset_validation,
    batch_size=4,
    shuffle=False,
    collate_fn=utils.collate_fn
)
```

**Breakdown:** \
- stepwise breakdown \

#### Instantiating Plate_Image_Dataset class and creating training and validation subsets...
```{python}
num_epochs = 10
precedent_epoch = 0

epoch, loss_metrics = helper_training_functions.train(model, data_loader, data_loader_test, device, num_epochs, precedent_epoch)

eval_metrics = helper_training_functions.evaluate_model(model, data_loader_test,device)

helper_training_functions.plot_eval_metrics(eval_metrics, epoch)


print("\n -end-")
)
```

**Breakdown:** \
- stepwise breakdown \


### Next step:
